FROM tensorflow/tensorflow:1.12.0-gpu-py3 
RUN apt-get update

# docker build -f ./mainDockerfile -t imagequery_main:raft .
# docker run --runtime=nvidia -p 10000:10000 -it imagequery_main:raft

# /container would contains:
# c0_entryContainer c1_speechRecognition/ c2_imageCaptionGenerator/ c3_nlpMappingGenerator/ c4_questionAnswering/ main.py
 
### for c0
ADD c0_entryContainer/app /container/c0_entryContainer

### for c1 
RUN apt-get install wget zip unzip python3 python3-pip -y
RUN pip3 install SpeechRecognition
RUN apt-get install -y swig libpulse-dev libasound2-dev
RUN pip3 install pocketsphinx
RUN apt-get install curl -y
RUN apt-get install ffmpeg -y
RUN pip3 install pydub
RUN apt-get install ffmpeg libavcodec-extra -y
RUN pip3 install glob3

ADD c1_speechRecognition/app /container/c1_speechRecognition
ADD c1_speechRecognition/data /container/c1_speechRecognition/data

RUN chmod 777 /container/c1_speechRecognition/data/dataset3/downloadDataset.sh
RUN /container/c1_speechRecognition/data/dataset3/downloadDataset.sh
RUN mv $(find / -name speech-accent-archive.zip) /container/c1_speechRecognition/data/dataset3
RUN unzip /container/c1_speechRecognition/data/dataset3/speech-accent-archive.zip -d /container/c1_speechRecognition/data/dataset3
RUN unzip -qq /container/c1_speechRecognition/data/dataset3/recordings.zip -d /container/c1_speechRecognition/data/dataset3/
RUN chmod 777 /container/c1_speechRecognition/data/dataset3/rename.sh
RUN /container/c1_speechRecognition/data/dataset3/rename.sh
RUN python3 /container/c1_speechRecognition/data/dataset3/truncate.py

### for c2 
RUN pip3 install numpy nltk
RUN python3 -m nltk.downloader all
RUN apt install wget

# copy files into image
ADD c2_imageCaptionGenerator/app /container/c2_imageCaptionGenerator/
ADD c2_imageCaptionGenerator/captionData /container/c2_imageCaptionGenerator/captionData
ADD c2_imageCaptionGenerator/im2txt/ /container/c2_imageCaptionGenerator/im2txt/
ADD c2_imageCaptionGenerator/im2txt/ops/ /container/c2_imageCaptionGenerator/ops/
 
# download pre-trained models 
RUN chmod 777 /container/c2_imageCaptionGenerator/im2txt/model/downloadModels.sh
RUN /container/c2_imageCaptionGenerator/im2txt/model/downloadModels.sh
RUN mv /notebooks/newmodel.ckpt-2000000.meta /container/c2_imageCaptionGenerator/im2txt/model
RUN mv /notebooks/newmodel.ckpt-2000000.data-00000-of-00001 /container/c2_imageCaptionGenerator/im2txt/model

# download datasets, untar and reindex images.
RUN wget --progress=bar:force http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz
RUN mv /notebooks/101_ObjectCategories.tar.gz /container/c2_imageCaptionGenerator/im2txt/data/imageDataset
RUN chmod 777 /container/c2_imageCaptionGenerator/im2txt/data/imageDataset/untar.sh 
RUN /container/c2_imageCaptionGenerator/im2txt/data/imageDataset/untar.sh 
RUN chmod 777 /container/c2_imageCaptionGenerator/im2txt/data/imageDataset/rename.sh 
RUN /container/c2_imageCaptionGenerator/im2txt/data/imageDataset/rename.sh

### for c3 
RUN pip3 install nltk numpy textacy
RUN python3 -m nltk.downloader all
RUN pip3 install spacy
RUN python3 -m spacy download en_core_web_sm

ADD c3_nlpMappingGenerator/app /container/c3_nlpMappingGenerator

### for c4
ADD c4_questionAnswering/app /container/c4_questionAnswering

# for main.py
ADD closure.py /container
ADD rpc.py /container
ADD main.py /container

# /container nows contains: 
# c0_entryContainer c1_speechRecognition/ c2_imageCaptionGenerator/ c3_nlpMappingGenerator/ c4_questionAnswering/ main.py

# Crucial
WORKDIR /container

# CMD ["python", "/container/closure.py"]
CMD ["python3", "/container/main.py"]

EXPOSE 10000
