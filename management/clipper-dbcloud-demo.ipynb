{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import clipper_manager as cl\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.externals import joblib\n",
    "import sys\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to EC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if Docker running...\n",
      "Found Docker running\n",
      "Creating internal Docker network\n",
      "Creating local model repository\n"
     ]
    }
   ],
   "source": [
    "import clipper_manager as cl\n",
    "ec2_host = \"ec2-52-53-151-0.us-west-1.compute.amazonaws.com\"\n",
    "user = \"ubuntu\"\n",
    "key = os.path.expanduser(\"~/.ssh/aws_rsa\")\n",
    "clipper = cl.Cluster(ec2_host, user, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Clipper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Clipper with default settings:\n",
      "models = []\n",
      "redis_port = 6379\n",
      "use_lsh = false\n",
      "window_size = -1\n",
      "name = \"clipper-demo\"\n",
      "input_type = \"float\"\n",
      "num_update_workers = 1\n",
      "num_predict_workers = 1\n",
      "redis_ip = \"redis-clipper\"\n",
      "cache_size = 49999\n",
      "slo_micros = 20000\n",
      "correction_policy = \"logistic_regression\"\n",
      "input_length = 784\n",
      "[batching]\n",
      "sample_size = 1000\n",
      "strategy = \"aimd\"\n",
      "\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] sudo: docker run -d --network=clipper_nw -p 6379:6379 --cpuset-cpus=\"0\" --name redis-clipper redis:alpine\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] sudo: docker run -d --network=clipper_nw -p 1337:1337 --cpuset-cpus=\"1-4\" --name clipper -v ~/conf.toml:/tmp/conf.toml dcrankshaw/clipper\n"
     ]
    }
   ],
   "source": [
    "clipper.start_clipper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"meters\": [\n",
      "        {\n",
      "            \"rate\": 0.0, \n",
      "            \"name\": \"prediction_thruput\", \n",
      "            \"unit\": \"events per second\"\n",
      "        }, \n",
      "        {\n",
      "            \"rate\": 0.0, \n",
      "            \"name\": \"update_thruput\", \n",
      "            \"unit\": \"events per second\"\n",
      "        }\n",
      "    ], \n",
      "    \"histograms\": [\n",
      "        {\n",
      "            \"std\": 0.0, \n",
      "            \"p99\": 0.0, \n",
      "            \"name\": \"prediction_latency\", \n",
      "            \"min\": 0, \n",
      "            \"max\": 0, \n",
      "            \"p95\": 0.0, \n",
      "            \"p50\": 0.0, \n",
      "            \"mean\": 0.0\n",
      "        }, \n",
      "        {\n",
      "            \"std\": 0.0, \n",
      "            \"p99\": 0.0, \n",
      "            \"name\": \"in_time_predictions\", \n",
      "            \"min\": 0, \n",
      "            \"max\": 0, \n",
      "            \"p95\": 0.0, \n",
      "            \"p50\": 0.0, \n",
      "            \"mean\": 0.0\n",
      "        }, \n",
      "        {\n",
      "            \"std\": 0.0, \n",
      "            \"p99\": 0.0, \n",
      "            \"name\": \"update_latency\", \n",
      "            \"min\": 0, \n",
      "            \"max\": 0, \n",
      "            \"p95\": 0.0, \n",
      "            \"p50\": 0.0, \n",
      "            \"mean\": 0.0\n",
      "        }\n",
      "    ], \n",
      "    \"ratio_counters\": [\n",
      "        {\n",
      "            \"ratio\": null, \n",
      "            \"name\": \"prediction accuracy ratio\"\n",
      "        }, \n",
      "        {\n",
      "            \"ratio\": null, \n",
      "            \"name\": \"cache_hits\"\n",
      "        }\n",
      "    ], \n",
      "    \"name\": \"clipper-demo\", \n",
      "    \"counters\": [\n",
      "        {\n",
      "            \"count\": 0, \n",
      "            \"name\": \"prediction_counter\"\n",
      "        }, \n",
      "        {\n",
      "            \"count\": 0, \n",
      "            \"name\": \"queued_predictions\"\n",
      "        }, \n",
      "        {\n",
      "            \"count\": 0, \n",
      "            \"name\": \"update_counter\"\n",
      "        }, \n",
      "        {\n",
      "            \"count\": 0, \n",
      "            \"name\": \"queued_updates\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print json.dumps(clipper.get_metrics(), indent=4)\n",
    "clipper.list_apps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a serving workload\n",
    "\n",
    "We go to a [different notebook](run_serving_workload.ipynb) so we can start querying the model from a separate process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Scikit-Learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source file: /Users/crankshaw/model-serving/data/mnist_data/train.data\n",
      "Number of image files: 60000\n",
      "Source file: /Users/crankshaw/model-serving/data/mnist_data/test.data\n",
      "Number of image files: 10000\n"
     ]
    }
   ],
   "source": [
    "def load_digits(digits_location, digits_filename = \"train.data\", norm=True):\n",
    "    digits_path = digits_location + \"/\" + digits_filename\n",
    "    print(\"Source file: %s\" % digits_path)\n",
    "    df = pd.read_csv(digits_path, sep=\",\", header=None)\n",
    "    data = df.values\n",
    "    print(\"Number of image files: %d\" % len(data))\n",
    "    y = data[:,0]\n",
    "    X = data[:,1:]\n",
    "    Z = X\n",
    "    if norm:\n",
    "        mu = np.mean(X,0)\n",
    "        sigma = np.var(X,0)\n",
    "        Z = (X - mu) / np.array([np.sqrt(z) if z > 0 else 1. for z in sigma])\n",
    "    return Z, y\n",
    "\n",
    "def filter_data(data):\n",
    "    cx, cy = data\n",
    "    binary_x = []\n",
    "    binary_y = []\n",
    "    for i in range(len(cy)):\n",
    "        if cy[i] == 3:\n",
    "            binary_x.append(cx[i,:])\n",
    "            binary_y.append(1.0)\n",
    "        elif cy[i] == 6:\n",
    "            binary_x.append(cx[i,:])\n",
    "            binary_y.append(0.0)\n",
    "    return np.array(binary_x), np.array(binary_y)\n",
    "            \n",
    "train_x, train_y = filter_data(load_digits(os.path.expanduser(\"~/model-serving/data/mnist_data\")))\n",
    "test_x, test_y = filter_data(load_digits(os.path.expanduser(\"~/model-serving/data/mnist_data\"), digits_filename=\"test.data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a bad model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79469854469854473"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RFC(n_estimators=2, max_depth=1)\n",
    "rf_model.fit(train_x, train_y)\n",
    "rf_model.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy A Bad Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/clipper-models/bad_rf_model/1\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] sudo: docker run -d --network=clipper_nw --name bad_rf_model_v1_r0 -v /tmp/clipper-models/bad_rf_model/1/bad_rf_model:/model:ro dcrankshaw/clipper-sklearn-mw\n"
     ]
    }
   ],
   "source": [
    "clipper.add_sklearn_model(\"bad_rf_model\", rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Spark Model\n",
    "\n",
    "Now let's go train a model using Spark in a Databricks Cloud [Notebook](https://amplab-berkeley-research.cloud.databricks.com/#notebook/46987).\n",
    "\n",
    "## Deploy a Spark Model from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/clipper-models/spark_svm/1\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] run: aws s3 cp s3://clipperdbdemo/spark_svm_model/svm_predict_3 /tmp/clipper-models/spark_svm/1/svm_predict_3 --recursive\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] out: download: s3://clipperdbdemo/spark_svm_model/svm_predict_3/data/_SUCCESS to svm_predict_3/data/_SUCCESS\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] out: Completed 1 of 6 part(s) with 5 file(s) remaining\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] out: download: s3://clipperdbdemo/spark_svm_model/svm_predict_3/metadata/_SUCCESS to svm_predict_3/metadata/_SUCCESS\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] out: Completed 2 of 6 part(s) with 4 file(s) remaining\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] out: download: s3://clipperdbdemo/spark_svm_model/svm_predict_3/metadata/part-00000 to svm_predict_3/metadata/part-00000\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] out: Completed 3 of 6 part(s) with 3 file(s) remaining\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] out: download: s3://clipperdbdemo/spark_svm_model/svm_predict_3/data/_common_metadata to svm_predict_3/data/_common_metadata\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] out: Completed 4 of 6 part(s) with 2 file(s) remaining\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] out: download: s3://clipperdbdemo/spark_svm_model/svm_predict_3/data/_metadata to svm_predict_3/data/_metadata\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] out: Completed 5 of 6 part(s) with 1 file(s) remaining\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] out: download: s3://clipperdbdemo/spark_svm_model/svm_predict_3/data/part-r-00000-617453e6-2671-4674-a07d-47d0fb49871e.gz.parquet to svm_predict_3/data/part-r-00000-617453e6-2671-4674-a07d-47d0fb49871e.gz.parquet\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] out: \n",
      "\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] sudo: docker run -d --network=clipper_nw --name spark_svm_v1_r0 -v /tmp/clipper-models/spark_svm/1/svm_predict_3:/model:ro dcrankshaw/clipper-spark-mw\n"
     ]
    }
   ],
   "source": [
    "clipper.add_pyspark_model(\"spark_svm\", \"s3://clipperdbdemo/spark_svm_model/svm_predict_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an SVM with RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99480249480249483"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = svm.SVC()\n",
    "svm_model.fit(train_x, train_y)\n",
    "svm_model.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/clipper-models/rbf_svm_model/1\n",
      "[ec2-52-53-151-0.us-west-1.compute.amazonaws.com] sudo: docker run -d --network=clipper_nw --name rbf_svm_model_v1_r0 -v /tmp/clipper-models/rbf_svm_model/1/rbf_svm_model:/model:ro dcrankshaw/clipper-sklearn-mw\n"
     ]
    }
   ],
   "source": [
    "clipper.add_sklearn_model(\"rbf_svm_model\", svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"linear_model\": {\n",
      "        \"label\": [\n",
      "            1, \n",
      "            0\n",
      "        ], \n",
      "        \"bias\": -1.0, \n",
      "        \"nr_class\": 2, \n",
      "        \"w\": [\n",
      "            1.9580837366019657, \n",
      "            0.6497062643846426, \n",
      "            -0.02436218717027392\n",
      "        ], \n",
      "        \"nr_feature\": 3\n",
      "    }, \n",
      "    \"anytime_estimators\": [\n",
      "        0.56, \n",
      "        0.6, \n",
      "        0.52\n",
      "    ], \n",
      "    \"offline_model_order\": [\n",
      "        \"rbf_svm_model\", \n",
      "        \"spark_svm\", \n",
      "        \"bad_rf_model\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print json.dumps(clipper.get_correction_model(0), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send some corrections\n",
    "\n",
    "We go to a [different notebook](send_updates.ipynb) to send more training data to Clipper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Clipper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clipper.stop_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm_model = lm.LogisticRegression()\n",
    "lm_model.fit(train_x, train_y)\n",
    "lm_model.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clipper.add_replicas(\"bad_rf_model\", 1, num_replicas=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
